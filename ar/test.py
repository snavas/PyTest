'''
Author: Zhaorui Chen 2017
Code based on OpenCV doc - python tutorial.
'''

# The intrinsic parameters for macbook-pro early 2015
# generated using AR toolbox
k1=0.0
k2=-0.0
p1=0.0
p2=-0.0
fx=924.161
fy=923.598
x0=637.264
y0=360.593
s=0.957716

import argparse
import cv2
import numpy as np
from matplotlib import pyplot as plt
from ar.ROI import ROI
from ar.Matcher import Matcher
from classes.realsense import RealSense
import argparse

# Set up the intrinsix matrices
disCoeff = np.float32([k1, k2, p1, p2])
cameraMatrix = np.float32([[fx, 0.0, x0], [0.0, fy, y0],[0.0,0.0,1.0]])

class App:
	#def __init__(self, alg, mode):
	def __init__(self):
		self.referencePoints = []
		self.cropping = False
		self.roi = None # the marker object
		self.alg = "sift" # the algorithm to choose: sift/orb
		self.mode = "static" # the way of choosing marker: static/screen capture


	# Code borrowed from:
	#	http://www.pyimagesearch.com/2015/03/09/capturing-mouse-click-events-with-python-and-opencv/
	def click_and_crop(self, event, x, y, flags, param):

		# if the left mouse button was clicked, record the starting
		# (x, y) coordinates and indicate that cropping is being
		# performed
		if event == cv2.EVENT_LBUTTONDOWN:
			self.referencePoints = [(x, y)]
			self.cropping = True

		# check to see if the left mouse button was released
		elif event == cv2.EVENT_LBUTTONUP:
			# record the ending (x, y) coordinates and indicate that
			# the cropping operation is finished
			self.referencePoints.append((x, y))
			self.cropping = False


	def draw(self, img, corners, imgpts):
		corner = tuple(corners[0].ravel())
		img = cv2.line(img, corner, tuple(imgpts[0].ravel()), (255,0,0), 5)
		img = cv2.line(img, corner, tuple(imgpts[1].ravel()), (0,255,0), 5)
		img = cv2.line(img, corner, tuple(imgpts[2].ravel()), (0,0,255), 5)
		return img

	def main(self):

		''' Screencapture from the webcam frame to get the marker pattern '''

		#cap = cv2.VideoCapture(0)
		device = RealSense()
		#cap = image1 = device.getcolorstream()

		if self.mode == 'capture':
			while True:

				# Capture frame-by-frame
				frame = device.getcolorstream()

				currentFrame = frame.copy()
				cv2.namedWindow("choose marker")
				cv2.setMouseCallback("choose marker", self.click_and_crop)

				# Display the resulting frame
				cv2.imshow('choose marker',frame)

				# if there are two reference points, then crop the region of interest
				# from teh image and display it
				if len(self.referencePoints) == 2:
					cropImage = currentFrame[self.referencePoints[0][1]:self.referencePoints[1][1], \
							self.referencePoints[0][0]:self.referencePoints[1][0]]
					cv2.rectangle(currentFrame, self.referencePoints[0], self.referencePoints[1], (0, 255, 0), 2)
					# initialize a marker object for the marker
					self.roi = ROI(cropImage, self.alg)

					cv2.imshow('choose marker',currentFrame)
					cv2.waitKey(1000)
					cv2.destroyWindow('choose marker')
					break

				if cv2.waitKey(1) & 0xFF == ord('q'):
					cap.release()
					cv2.destroyAllWindows()
					break
		else:
			roi = cv2.imread('models/64.png')
			self.roi = ROI(roi, self.alg)



		''' Handling the logic for marker pattern matching '''

		cv2.waitKey(100)
		matcher = Matcher(self.roi, self.alg, disCoeff, cameraMatrix)

		while True:
			# Capture frame-by-frame
			ret, frame = cap.read()
			currentFrame = frame.copy()
			mirrorFrame = cv2.resize(frame, (0,0), fx=0.3, fy=0.3)

			'''
			plt.subplot(2,1,1),plt.imshow(self.roi.image)
			plt.subplot(2,1,2),plt.imshow(currentFrame)
			plt.show()
			'''

			cv2.namedWindow('webcam')
			cv2.imshow('webcam', currentFrame)

			matcher.setFrame(currentFrame)


			result = matcher.getCorrespondence()
			if result:
				# get the corners
				(src, dst, corners) = result
			else:
				# Not enough matching points found
				print('Not enough points')
				cv2.waitKey(1)
				continue

			(retvalCorner, rvecCorner, tvecCorner) = matcher.computePose(self.roi.getPoints3d(), corners)
			if retvalCorner:
				# Set up where to draw the axises of the the cube in the frame
				axis = np.float32([[0,0,0], [0,1,0], [1,1,0], [1,0,0], [0,0,-1],[0,1,-1],[1,1,-1],[1,0,-1] ])

				'''
				cv2.projectPoints(objectPoints, rvec, tvec, cameraMatrix, distCoeffs
					[, imagePoints[, jacobian[, aspectRatio]]])
				â†’ imagePoints, jacobian
				'''
				# project 3d points to 2d coordinates in the frame coordination
				imgpts, jac = cv2.projectPoints(axis, rvecCorner, tvecCorner, cameraMatrix, disCoeff)

				# re-draw the frame
				currentFrame = cv2.polylines(currentFrame,[np.int32(corners)],True,255,3, cv2.LINE_AA)
				currentFrame = self.renderImg(currentFrame, imgpts)

				cv2.imshow('webcam', currentFrame)
				#plt.subplot(2,1,2),plt.imshow(currentFrame)
				#plt.show()
				cv2.waitKey(1)

			else:
				#print('not able to solve pnp')
				cv2.waitKey(1)
				continue

			if cv2.waitKey(1) & 0xFF == ord('q'):
				cap.release()
				cv2.destroyAllWindows()
				break

	def renderImg(self, img, imgpts):
		imgpts = np.int32(imgpts).reshape(-1,2)

		# draw floor in grey
		img = cv2.drawContours(img, [imgpts[:4]],-1,(175,175,175),-3)

		# draw pillars in blue color
		for i,j in zip(range(4),range(4,8)):
			img = cv2.line(img, tuple(imgpts[i]), tuple(imgpts[j]),(255),3)

		return img


if __name__ == '__main__':

	#parser = argparse.ArgumentParser()
	#parser.add_argument("mode", help="choose the program mode from {static, capture}, static will use the image named roi.png in the same directory")
	#parser.add_argument("algorithm", help="choose the feature extraction algorithm from {sift, orb}")
	#args = parser.parse_args()

	app = App()
	app.main()